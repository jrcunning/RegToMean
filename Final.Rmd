---
title: "Example"
author: "Ross Cunning"
date: "2025-04-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r libraries}
# Load libraries
library(tidyverse)
library(ggpubr)
library(broom)
```

```{r functions}
# Define helper functions

# Function to test if slopes are significantly different from null slope
slope_test <- function(model, null_slope = 0, alternative = c("less", "greater", "two.sided")) {
  alternative <- match.arg(alternative)

  # Extract slope estimate and SE
  coefs <- summary(model)$coefficients
  slope_est <- coefs[2, "Estimate"]
  slope_se  <- coefs[2, "Std. Error"]
  df_resid  <- model$df.residual

  # Compute t-statistic
  t_stat <- (slope_est - null_slope) / slope_se

  # Compute p-value
  p_val <- switch(alternative,
                  less = pt(t_stat, df = df_resid),
                  greater = 1 - pt(t_stat, df = df_resid),
                  two.sided = 2 * pt(-abs(t_stat), df = df_resid))

  # Map alternative to null hypothesis symbol
  null_symbol <- switch(alternative,
                        less = "≥",
                        greater = "≤",
                        two.sided = "=")

  # Get predictor and response variable names
  terms <- all.vars(formula(model))
  xvar <- terms[2]
  yvar <- terms[1]
  data <- model$model

  # Create ggplot layers
  line_layer <- geom_smooth(method = "lm", se = FALSE, color = "blue")
  text_layer <- annotate("text", color = "blue",
                         x = min(data[[xvar]], na.rm = TRUE),
                         y = max(data[[yvar]], na.rm = TRUE),
                         label = paste0("Slope = ", round(slope_est, 3),
                                        "\nP (H0: slope ", null_symbol, " ", null_slope, ") = ",
                                        signif(p_val, 3)),
                         hjust = 0, vjust = 1)

  list(line = line_layer, annotation = text_layer)
}



# Function to correct for spurious slopes, from Kelly and Price 2005
rttm.adj <- function(m1, m2){
  raw.growth<-m2-m1
  vart<-var.test(m1,m2,paired = T) ## variances equal? 
  vpv<-vart$p.value # var.test p value
  m1m2cor<-cor.test(m1, m2) # test correlation between m1 and m2 
  rho<-m1m2cor$estimate # correlation coefficient between m1 and m2 
  m1sd<-sd(m1) # m1 sd
  m2sd<-sd(m2) # m2 sd
  m1v<-var(m1) # m1 var
  m2v<-var(m2) # m2 var
  m1m<-mean(m1) # m1 mean
  m2m<-mean(m2) # m2 mean
  pm<-mean(raw.growth)
  rho2<-(2*rho*m1sd*m2sd)/(m1v+m2v) # adjusted correlation coefficient used if variances are equal
  rhof<-ifelse(vpv <= 0.05, rho, rho2) # which rho is used for dstar calculation is based on variance comparison
  dstar<-(rhof*(m1-m1m)-(m2-m2m))*-1 # adjustment values. Multiply by -1 to flip sign because Kelly and Price based on plasticity as m1-m2, not m2-m1 as in most thermal tolerance estimates
  adj.growth <- pm+dstar # corrected plasticity. 
  out<-as.data.frame(cbind(raw.growth, dstar, adj.growth)) 
  return(out)
}
```

# Set parameters for simulations
```{r}
# Get mean and standard deviations from real data
pdam0 <- read_csv("PdamRbleaching.csv")
pdam_summ <- pdam0 %>% 
  group_by(sym) %>%
  summarise(across(c(juntotal, augtotal), 
                   list(mean = ~mean(log(.)), sd = ~sd(log(.)))))

# Get mean initial S/H in each group corals (jun)
pdam.mean.init <- mean(pdam_summ$juntotal_mean)
# Get mean final S/H in each group of corals (aug)
pdam.mean.final <- mean(pdam_summ$augtotal_mean)

# Get average SD of S/H ratio in each group of corals (symbiont / timepoint)
pdam.sd <- mean(c(pdam_summ$juntotal_sd, pdam_summ$augtotal_sd))

# Get mean and SD of log changes in S/H ratio across all corals
pdam.mean.logchange <- mean(log(pdam0$augtotal/pdam0$juntotal))
pdam.sd.logchange <- sd(log(pdam0$augtotal/pdam0$juntotal))

pdam0 %>% 
  mutate(logchange = log(augtotal/juntotal)) %>%
  group_by(sym) %>%
  summarise(sd = sd(logchange),
            sdresid = sd(resid(lm(logchange~juntotal))))
  

# Set number of individuals for simulations
n <- 1000
```

# Population variance among individuals (σ²_among), individual variance, measurement variance

Three sources of variance
+ Variance among individuals in the true value (population variance; *v_pop*)
+ Variance in within-individual changes over time (individual-level variance; *v_ind*)
+ Variance due to noice or imprecision in measurement (error variance; *v_err*))

# Scenario 1

### No relationship between change and initial
### v_pop == v_ind == v_err

```{r s1}
# Set variances
v_pop <- 1
v_ind <- 1
v_err <- 1

# Simulate data
set.seed(1)
df1 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df1 <- df1 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Plot
p1 <- ggplot(df1, aes(x = log_init_true, y = log_final_true)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  stat_cor() +
  geom_smooth(method = "lm", se = FALSE) +
  xlim(-4, 4) + ylim(-5, 5)
p2 <- ggplot(df1, aes(x = log_init_true, y = log_change_true)) +
  geom_point(alpha = 0.25) +
  geom_abline(slope = 0, intercept = 0, linetype = "dashed") +
  stat_cor() +
  geom_smooth(method = "lm", se = FALSE) +
  xlim(-4, 4) + ylim(-3, 3)
p3 <- p2 + aes(x = log_init_true, y = log_change_true_adj)
p4 <- p1 + aes(x = log_init_obs, y = log_final_obs)
p5 <- p2 + aes(x = log_init_obs, y = log_change_obs)
p6 <- p2 + aes(x = log_init_obs, y = log_change_obs_adj)

plots1 <- list(p1, p2, p3, p4, p5, p6)

plots1panel <- ggpubr::ggarrange(plotlist = plots1, nrow = 2, ncol = 3, labels = "AUTO")

plots1panel
```

+ **A** confirms positive (but imperfect) correlation between true initial and final values (biologically realistic)
+ **B** confirms no relationship between true change and true initial (because simulated independently)
+ **C** confirms Kelly and Price correction on true values yields false positive correlation between change and initial (because initial and final imperfectly correlated due to individual variation)
+ **D** confirms positive (but more imperfect, compare to **A**) correlation between initial and final values observed with measurement error
+ **E** confirms spurious negative relationship between observed change and initial is due to measurement error (compare to **B**)
+ **F** confirms Kelly and Price correction on observed values yields false positive correlation, but weak (compare to **C**) (this becomes statistically significant at higher n)


# Scenario 2

### No relationship between change and initial
### v_pop == v_err >>> v_ind

```{r s2}
# Set variances
v_pop <- 1
v_ind <- 0.001
v_err <- 1

# Simulate data
set.seed(1)
df2 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df2 <- df2 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Update list of plots with scenario 2 data
plots2 <- map(plots1, ~ .x %+% df2)

# Create multipanel plot
plots2panel <- ggpubr::ggarrange(plotlist = plots2, nrow = 2, ncol = 3, labels = "AUTO")

# Display plots
plots2panel
```

+ Confirms when variance in observed change is mostly due to measurement error, Kelly Price adjustment recovers the correct zero relationship between observed change and initial (see **F**)

# Scenario 3

### No relationship between change and initial
### v_pop == v_ind >>> v_err

```{r s3}
# Set variances
v_pop <- 1
v_ind <- 1
v_err <- 0.001

# Simulate data
set.seed(1)
df3 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df3 <- df3 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Update list of plots with scenario 3 data
plots3 <- map(plots1, ~ .x %+% df3)

# Create multipanel plot
plots3panel <- ggpubr::ggarrange(plotlist = plots3, nrow = 2, ncol = 3, labels = "AUTO")

# Display plots
plots3panel
```

+ Confirms that when variance in observed change is mostly due to true variation in individual responses, Kelly Price adjustment yields a strong spurious positive correlation between observed change and initial (see **F**)

# Scenario 4

### True negative relationship between change and initial
### v_pop == v_ind == v_err

```{r s4}
# Set variances
v_pop <- 1
v_ind <- 1
v_err <- 1

# Set strength of true relationship
b <- -0.2

# Simulate data
set.seed(1)
df4 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = b * scale(log_init_true)[,1] + rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df4 <- df4 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Update list of plots with scenario 3 data
plots4 <- map(plots1, ~ .x %+% df4)

# Create multipanel plot
plots4panel <- ggpubr::ggarrange(plotlist = plots4, nrow = 2, ncol = 3, labels = "AUTO")

# Display plots
plots4panel
```

+ Confirms that when there is a true negative relationship between initial and change, Kelly Price adjustment yields a false positive correlation between initial and change (see **C**), and a false zero correlation between observed initial and change (see **F**).

# Scenario 5

### True negative relationship between change and initial
### v_pop == v_err >>> v_ind

```{r s5}
# Set variances
v_pop <- 1
v_ind <- 0.001
v_err <- 1

# Set strength of true relationship
b <- -0.2

# Simulate data
set.seed(1)
df5 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = b * scale(log_init_true)[,1] + rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df5 <- df5 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Update list of plots with scenario 3 data
plots5 <- map(plots1, ~ .x %+% df5)

# Create multipanel plot
plots5panel <- ggpubr::ggarrange(plotlist = plots5, nrow = 2, ncol = 3, labels = "AUTO")

# Display plots
plots5panel
```

+ Confirms when variance in observed change is mostly due to measurement error, Kelly Price adjustment yields true negative relationship between true change and initial (see **C**), but a false zero relationship between observed change and initial (see **F**).

# Scenario 6

### True negative relationship between change and initial
### v_pop == v_ind >>> v_err

```{r s5}
# Set variances
v_pop <- 1
v_ind <- 1
v_err <- 0.001

# Set strength of true relationship
b <- -0.2

# Simulate data
set.seed(1)
df6 <- tibble(
  log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
  log_change_true = b * scale(log_init_true)[,1] + rnorm(n, mean = 0, sd = sqrt(v_ind)),        # Independent 0 change plus individual response variation
  # Later: Check if FINAL can be simulated to then derive change, and if this is equivalent
  log_final_true = log_init_true + log_change_true,           # Final = initial + change
  e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)  

# Apply Kelly Price correction to true values and observed values
df6 <- df6 %>% mutate(
  log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3],
  log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
)
  
# Update list of plots with scenario 3 data
plots6 <- map(plots1, ~ .x %+% df6)

# Create multipanel plot
plots6panel <- ggpubr::ggarrange(plotlist = plots6, nrow = 2, ncol = 3, labels = "AUTO")

# Display plots
plots6panel
```

+ Confirms that when variance in observed change is mostly due to true variation in individual responses, Kelly Price adjustment yields a false positive correlation between true change and initial (see **C**), and a false positive correlation between observed change and initial (see **F**).

# Test combinations of var_ind, var_err, and b to see when KP adjustment recovers true or false relationship between observed change and initial

```{r}
pars <- expand_grid(
  v_pop = 1,
  v_ind = seq(0, 1, 0.1),
  v_err = seq(0, 1, 0.1),
  b = seq(-0.4, 0.4, 0.1)
)

test.cors <- function(v_pop, v_ind, v_err, b) {
  # Simulate data
  df <- tibble(
    log_init_true = rnorm(n, mean = 0, sd = sqrt(v_pop)),
    log_change_true = b * scale(log_init_true)[,1] + rnorm(n, mean = 0, sd = sqrt(v_ind)),   
    log_final_true = log_init_true + log_change_true,           # Final = initial + change
    e_init = rnorm(n, mean = 0, sd = sqrt(v_err)),          # Random measurement error for initial values
    e_final = rnorm(n, mean = 0, sd = sqrt(v_err)),         # Random measurement error for final values
    log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
    log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
    log_change_obs = log_final_obs - log_init_obs   # Observed change
  )
  # Apply Kelly Price correction to observed values
  df <- df %>% mutate(
    log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3]
  )
  # Get true, observed, and adjusted correlations between change and initial
  bind_rows(.id = "cor.type",
      #true = tidy(cor.test(df$log_change_true, log_init_true)),
      obs = tidy(cor.test(df$log_change_obs, df$log_init_obs)),
      adj = tidy(cor.test(df$log_change_obs_adj, df$log_init_obs))
  ) %>% bind_cols(
    v_pop = v_pop,
    v_ind = v_ind,
    v_err = v_err,
    b = b
  )
}

# Run the function on all parameter combinations and bind results
results <- pmap_dfr(pars, test.cors) %>%
  select(v_pop, v_ind, v_err, b, cor.type, estimate, p.value) %>%
  mutate(outcome = case_when(
    p.value > 0.01 & b == 0 ~ "correct",
    p.value > 0.01 & b != 0 ~ "type2 - misses effect that does exist",
    p.value < 0.01 & sign(estimate) != sign(b) ~ "type1 - detects effect that does not exist",
    p.value < 0.01 & sign(estimate) == sign(b) ~ "correct"
  ))

# Get the parameters, correlation coefficients, and statistical significance for each simulation
# (b, and estimates based on true, observed, and adjusted values)
results_summ <- results %>%
  pivot_wider(id_cols = c(v_pop, v_ind, v_err, b),
              names_from = cor.type,
              values_from = outcome) %>%
  mutate(which = case_when(obs == "correct" & adj == "incorrect" ~ "obs",
                           obs == "incorrect" & adj == "correct" ~ "adj",
                           obs == "correct" & adj == "correct" ~ "both",
                           obs == "incorrect" & adj == "incorrect" ~ "neither"))

ggplot(results, aes(x = v_ind, y = v_err)) +
  geom_point(aes(shape = cor.type, size = cor.type, color = outcome), alpha = 0.5) +
  facet_wrap(~b) +
  scale_color_manual(values = c("forestgreen", "red", "blue", "gray")) +
  scale_shape_manual(values = c(16, 15))
  # scale_size_manual(values = c(7,5))

ggplot(results_summ, aes(x = v_ind, y = v_err)) +
  geom_point(aes(shape = which, color = which)) +
  facet_wrap(~b)
```













########
# Scenario : Relative change is unrelated to initial value; values are measured with error
```{r s2.1}
# Final vs. Initial, observed values with measurement error
# Expect: slope ≈ 1
mod2.1 <- lm(log_final_obs ~ log_init_obs, data = df1)
res2.1 <- slope_test(mod2.1, 1, "less")
p2.1 <- ggplot(df1, aes(x = log_init_obs, y = log_final_obs)) +
  geom_point(alpha = 0.25) +
  res2.1$line +
  res2.1$annotation +
  theme_minimal() +
  labs(title = "Final vs. initial (no relationship; with measurement error)")

# Change vs. initial, observed values with measurement error
# Expect: slope ≈ 0
mod2.2 <- lm(log_change_obs ~ log_init_obs, data = df1)
res2.2 <- slope_test(mod2.2, 0, "less")
p2.2 <- ggplot(df1, aes(x = log_init_obs, y = log_change_obs)) +
  geom_point(alpha = 0.25) +
  res2.2$line +
  res2.2$annotation +
  theme_minimal() +
  labs(title = "Change vs. initial (no relationship; with measurement error)")

p2.2
```

Shows measurement error in initial values leads to mathematical coupling and spurious relationship

### Does the Kelly and Price method recover correct relationship (slope = 0)?
```{r s2.2}
# Apply Kelly and Price method to get adjusted change
df1 <- df1 %>%
  mutate(log_change_obs_adj = rttm.adj(log_init_obs, log_final_obs)[, 3])

# Model adjusted change vs. initial values
mod2.3 <- lm(log_change_obs_adj ~ log_init_obs, data = df1)
res2.3 <- slope_test(mod2.3, 0, "less")
p2.3 <- ggplot(df1, aes(x = log_init_obs, y = log_change_obs_adj)) +
  geom_point(alpha = 0.25) +
  res2.3$line +
  res2.3$annotation +
  theme_minimal() +
  labs(title = "K-P adjusted change vs. initial (no relationship; with measurement error)")

p2.3
```

Yes, Kelly and Price removes the spurious relationship caused by mathematical coupling. It is also able to do this when the measurement error is more extreme (tested with sd = 1).

It appears to be OVERcorrecting-- slight positive correlation -- is it because it could not differentiate the individual variation in change from the measurement error???


# Scenario 3: True negative relationship between change and initial values
```{r 3.1}
# Goal: Simulate a case where more symbionts causes greater loss (true relationship)

# Define strength of initial value effect on logchange
# e.g., -0.2 means for every 1 unit increase in initial, 0.2 unit decrease in logchange
b <- -0.5

# Define intercept to target 75% loss at mean initial value
#intercept <- log(0.25) - b * mean(df2$log_init_true)

# Simulate log changes as an intercept + effect of initial value + noise
set.seed(1)
df3 <- tibble(
  log_init_true = rnorm(n, mean = pdam.mean.init, sd = pdam.sd),
  log_change_true = log(0.25) + b * log_init_true + rnorm(n, mean = 0, sd = 0.3),  # Greater losses for higher initials
  log_final_true = log_init_true + log_change_true,     # True final values
  e_init = rnorm(n, mean = 0, sd = 0.3),          # Random measurement error for initial values
  e_final = rnorm(n, mean = 0, sd = 0.3),         # Random measurement error for final values
  log_init_obs = log_init_true + e_init,          # Add random measurement error to initial values
  log_final_obs = log_final_true + e_final,       # Add random measurement error to final values
  log_change_obs = log_final_obs - log_init_obs   # Observed change
)


# Final vs. initial, true values
# Expected: slope = 0.8
mod3.1 <- lm(log_final_true ~ log_init_true, data = df3)
res3.1 <- slope_test(mod3.1, 1, "less")
p3.1 <- ggplot(df3, aes(x = log_init_true, y = log_final_true)) +
  geom_point(alpha = 0.25) +
  res3.1$line +
  res3.1$annotation +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  theme_minimal() +
  labs(title = "Final vs. initial (true relationship; true values)")
p3.1

# Change vs. initial, true values
# Expected: slope = -0.2
mod3.2 <- lm(log_change_true ~ log_init_true, data = df3)
res3.2 <- slope_test(mod3.2, 0, "less")
p3.2 <- ggplot(df3, aes(x = log_init_true, y = log_change_true)) +
  geom_point(alpha = 0.25) +
  res3.2$line +
  res3.2$annotation +
  theme_minimal() +
  labs(title = "Change vs. initial (true relationship; true values)")

p3.2


```

### Does the Kelly and Price method change this relationship?
```{r s3.2}
# Apply Kelly and Price method to get adjusted change
df3 <- df3 %>%
  mutate(log_change_true_adj = rttm.adj(log_init_true, log_final_true)[, 3])

# Model adjusted change vs. initial values
mod3.3 <- lm(log_change_true_adj ~ log_init_true, data = df3)
res3.3 <- slope_test(mod3.3, 0, "less")
p3.3 <- ggplot(df3, aes(x = log_init_true, y = log_change_true_adj)) +
  geom_point(alpha = 0.25) +
  res3.3$line +
  res3.3$annotation +
  theme_minimal() +
  labs(title = "K-P adjusted change vs. initial (true relationship; true values)")

p3.3
```

Need to test this more, but it seems to reduce the relationship a lot, and all the way to zero for lower values of b. Potentially there's a threshold b effect size wheren the adjustment still produces a negative but diminished relationship

Does the measurement error part come into effect here???

IT HAS TO DO WITH THE SD OF THE NOISE IN LOG_CHANGE_TRUE -- COMPARE 0.3 (too much) TO 0.2 (not too much)

# Scenario 4: Real data
```{r s4}
pdam <- pdam0 %>%
  mutate(log_init_raw = log(juntotal),
         log_final_raw = log(augtotal),
         log_change = log_final_raw - log_init_raw)

# ggplot(pdam, aes(x = log_init_raw, y = log_change, shape = sym, color = sym)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE) +
#   theme_minimal()

# Remove symbiont effect
# Calculate grand mean
grand_mean_init <- mean(pdam$log_init_raw)
grand_mean_final <- mean(pdam$log_final_raw)
# Add sym-group residuals to grand mean
pdam <- pdam %>%
  group_by(sym) %>%
  mutate(group_resid_init = log_init_raw - mean(log_init_raw),
         group_resid_final = log_final_raw - mean(log_final_raw)) %>%
  ungroup() %>%
  mutate(log_init = grand_mean_init + group_resid_init,
         log_final = grand_mean_final + group_resid_final) %>%
  select(colony, sym, log_init_raw, log_final_raw, log_init, log_final) %>%
  mutate(log_change = log_final - log_init)

# ggplot(pdam, aes(x = log_init, y = log_change, shape = sym, color = sym)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE) +
#   theme_minimal()

# Check normality
shapiro.test(pdam$log_init)
shapiro.test(pdam$log_final)
shapiro.test(pdam$log_change)
# initial, final, and changes are all normally distributed
p4.1 <- ggplot(pdam, aes(x = log_init, y = log_final)) + 
  geom_point() + 
  coord_fixed() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_smooth(method = "lm", se = FALSE)
p4.1
var(pdam$log_init)
var(pdam$log_final)

# Change vs. initial, real data
# Expected: slope = -0.2
mod4.2 <- lm(log_change ~ log_init, data = pdam)
res4.2 <- slope_test(mod4.2, 0, "less")
p4.2 <- ggplot(pdam, aes(x = log_init, y = log_change)) +
  geom_point(alpha = 0.25) +
  res4.2$line +
  res4.2$annotation +
  theme_minimal() +
  labs(title = "Change vs. initial (real data)")

p4.2
```

### Does the Kelly and Price method change this relationship?
```{r s3.2}
# Apply Kelly and Price method to get adjusted change
pdam <- pdam %>%
  mutate(log_change_adj = rttm.adj(log_init, log_final)[, 3])

# Model adjusted change vs. initial values
mod4.3 <- lm(log_change_adj ~ log_init, data = pdam)
res4.3 <- slope_test(mod4.3, 0, "less")
p4.3 <- ggplot(pdam, aes(x = log_init, y = log_change_adj)) +
  geom_point(alpha = 0.25) +
  res4.3$line +
  res4.3$annotation +
  theme_minimal() +
  labs(title = "K-P adjusted change vs. initial (real data)")

p4.3
```


# Real data Million Acer growth
```{r}
mill <- tibble(subMil1) %>%
  filter(size > 0) %>%  # there are four rows where size = 0, filter out because will generate Inf
  filter(InitialSize > 2) %>%     # cutoff of 1 gives adjusted marginal sig, cutoff 2 nonsig
  mutate(init = InitialSize,
         final = size,
         change = final - init)
MVN::mvn(data = select(mill, init, final))     # NOT multivariate normal, violates Kelly and Price assumption...

# Change vs. initial
mod5.2 <- lm(change ~ init, data = mill)
res5.2 <- slope_test(mod5.2, 0, "greater")
p5.2 <- ggplot(mill, aes(x = init, y = change)) +
  geom_point(alpha = 0.25) +
  res5.2$line +
  res5.2$annotation +
  theme_minimal() +
  labs(title = "Change vs. initial")

p5.2

# Adjusted change
mill <- mill %>%
  mutate(change_adj = rttm.adj(init, final)[, 3])

mod5.3 <- lm(change_adj ~ init, data = mill)
res5.3 <- slope_test(mod5.3, 0, "greater")
p5.3 <- ggplot(mill, aes(x = init, y = change_adj)) +
  geom_point(alpha = 0.25) +
  res5.3$line +
  res5.3$annotation +
  theme_minimal() +
  labs(title = "Adjusted Change vs. initial")

p5.3
```

This reproduces Carly's analysis --- but problem of lognormal?

# log-transform size
```{r}
mill <- tibble(subMil1) %>%
  filter(size > 0) %>%  # there are four rows where size = 0, filter out because will generate Inf
  filter(InitialSize > 2) %>%    # cutoff of 1 gives adjusted marginal sig, cutoff 2 nonsig
  mutate(log_init = log(InitialSize),
         log_final = log(size),
         log_change = log_final - log_init)

# Change vs. initial
mod5.2 <- lm(log_change ~ log_init, data = mill)
res5.2 <- slope_test(mod5.2, 0, "less")
p5.2 <- ggplot(mill, aes(x = log_init, y = log_change)) +
  geom_point(alpha = 0.25) +
  res5.2$line +
  res5.2$annotation +
  theme_minimal() +
  labs(title = "Change vs. initial")

p5.2

# Adjusted change
mill <- mill %>%
  mutate(log_change_adj = rttm.adj(log_init, log_final)[, 3])

mod5.3 <- lm(log_change_adj ~ log_init, data = mill)
res5.3 <- slope_test(mod5.3, 0, "less")
p5.3 <- ggplot(mill, aes(x = log_init, y = log_change_adj)) +
  geom_point(alpha = 0.25) +
  res5.3$line +
  res5.3$annotation +
  theme_minimal() +
  labs(title = "Adjusted Change vs. initial")

p5.3


```


# Simulate initial and final values independently
```{r s6}
set.seed(1)
df6 <- tibble(
  log_init = rnorm(n, mean = pdam.mean.init, sd = pdam.sd),    # Initial values (log)
  log_final = log(0.25) + rnorm(n, mean = pdam.mean.init, sd = pdam.sd),  # Final values
  log_change = log_final - log_init
) 
ggplot(df6, aes(x = log_init, y = log_change)) + geom_point()

# When initial and change are related (change = final - init), then there is a relationship
df7 <- tibble(
  init = rnorm(n, mean = 1, sd = 0.2),
  final = rnorm(n, mean = 0.25, sd = 0.2),
  change = final - init
)

ggplot(df7, aes(x = init, y = final)) + geom_point()
summary(lm(change~init, data = df7))
summary(lm(final~init, data = df7))


# When initial and change are simulated independently, no relationship
df8 <- tibble(
  init = rnorm(n, mean = 1, sd = 0.2),
  change = rnorm(n, mean = -0.75, sd = 2),
  final = init + change
)

ggplot(df8, aes(x = init, y = change)) + geom_point()

```

# Simulate exponential growth
```{r}
library(tidyverse)

# Parameters
total_steps <- 1000
n_individuals <- 50
r <- 0.001
sigma <- 0.005
N0 <- 10

# Choose 10 evenly spaced time steps (sorted just in case)
measured_times <- round(seq(1, total_steps, length.out = 10))

# Simulate exponential growth with stochastic noise
size <- matrix(NA, nrow = total_steps, ncol = n_individuals)
size[1, ] <- N0

for (t in 2:total_steps) {
  growth_noise <- rnorm(n_individuals, mean = r, sd = sigma)
  size[t, ] <- size[t - 1, ] * exp(growth_noise)
}

# Build data frame of initial size and change in size between measured steps
df <- map_dfr(1:(length(measured_times) - 1), function(i) {
  t1 <- measured_times[i]
  t2 <- measured_times[i + 1]
  tibble(
    time = t1,
    individual = 1:n_individuals,
    initial_size = size[t1, ],
    final_size = size[t2, ],
    change_in_size = size[t2, ] - size[t1, ]
  )
})
df

(p1 <- ggplot(df, aes(x = initial_size, y = change_in_size)) + geom_point())      # LOG OF RAW DIFF
p1 + scale_x_log10() + scale_y_log10()

df <- df %>%
  mutate(log_change_ratio = log(final_size/initial_size),       # LOG RATIO
         log_change_diff = log(final_size) - log(initial_size),          # LOG RATIO 
         log_initial_size = log(initial_size),
         log_final_size = log(final_size),
         log_change_in_size_adj = rttm.adj(log_initial_size, log_final_size)[,3])

ggplot(df, aes(x = log_initial_size, y = log_change_diff)) + geom_point()
cor(df$log_initial_size, df$log_change_in_size)
ggplot(df, aes(x = log_initial_size, y = log_change_in_size_adj)) + geom_point()
cor(df$log_initial_size, df$log_change_in_size_adj)
```

Something about how with exp growth we're multiplying by the change rather than adding the change

```{r}
# Pdam -- adding vs multiplying logs?
pdam %>%
  mutate(log_change_add = log_final - log_init,
         log_change_mult = log_final/log_init)

ggplot(pdam, aes(x = log_init, y = log_change)) + geom_point()

ggplot(pdam, aes(x = log_init, y = log_change_adj)) + geom_point()

pdam <- pdam %>%
  mutate(initial = exp(log_init),
         final = exp(log_final),
         change_adj = exp(log_change_adj),
         final_adj = initial * change_adj)

ggplot(pdam, aes(x = initial, y = final_adj)) + 
  geom_point() + coord_fixed() + geom_abline(aes(slope = 1, intercept = 0))
ggplot(pdam, aes(x = initial, y = final)) + 
  geom_point() + coord_fixed() + geom_abline(aes(slope = 1, intercept = 0))

ggplot(pdam, aes(x = log_init, y = log(final_adj/initial))) + geom_point()
ggplot(pdam, aes(x = log(initial), y = log_change_adj)) + geom_point()
cor(pdam$log_init, pdam$log_change)
cor(pdam$log_init, pdam$log_change_adj)
```

